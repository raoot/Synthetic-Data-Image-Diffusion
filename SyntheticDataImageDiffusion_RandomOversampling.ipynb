{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "# import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "XIdwfHA08J6W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reference: https://github.com/Saurabh2805/kdd_cup_99/blob/master/KDD_CUP_99_dataset_1.ipynb\n",
        "# Label = 'intrusion_type'\n",
        "columns = ['duration','protocol_type','service','flag','src_bytes','dst_bytes','land','wrong_fragment','urgent','hot','num_failed_logins','logged_in','num_compromised','root_shell','su_attempted',\n",
        "'num_root','num_file_creations','num_shells','num_access_files','num_outbound_cmds',\n",
        "'is_host_login',\n",
        "'is_guest_login',\n",
        "'count',\n",
        "'srv_count',\n",
        "'serror_rate',\n",
        "'srv_serror_rate',\n",
        "'rerror_rate',\n",
        "'srv_rerror_rate',\n",
        "'same_srv_rate',\n",
        "'diff_srv_rate',\n",
        "'srv_diff_host_rate',\n",
        "'dst_host_count',\n",
        "'dst_host_srv_count',\n",
        "'dst_host_same_srv_rate',\n",
        "'dst_host_diff_srv_rate',\n",
        "'dst_host_same_src_port_rate',\n",
        "'dst_host_srv_diff_host_rate',\n",
        "'dst_host_serror_rate',\n",
        "'dst_host_srv_serror_rate',\n",
        "'dst_host_rerror_rate',\n",
        "'dst_host_srv_rerror_rate',\n",
        "'intrusion_type']"
      ],
      "metadata": {
        "id": "08eNXRe-ZOgB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('sample_data/kddcup.data_10_percent_testing.csv', names=columns, header=None)\n",
        "print(f\"Total rows and columns: {df.shape}\")"
      ],
      "metadata": {
        "id": "u_AOoCf5ZQ5X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a105aee-e525-43cf-befe-75a6d4046b31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total rows and columns: (494021, 42)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ordinal Encoding\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "\n",
        "columns_encode = ['protocol_type','service','flag','intrusion_type']\n",
        "df[columns_encode] = OrdinalEncoder().fit_transform(df[columns_encode])"
      ],
      "metadata": {
        "id": "fpMxNkhSZUBL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for NANs\n",
        "NANs_before = df.isna().sum().sum()\n",
        "print(f\"Number of NANs before removal: {NANs_before}\")\n",
        "df.dropna(inplace=True)\n",
        "NANs_after = df.isna().sum().sum()\n",
        "print(f\"Number of NaNs after removal: {NANs_after}\")"
      ],
      "metadata": {
        "id": "6BUYUd3oZxDt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e12c6aad-3ec3-4c30-ad48-d5a684b589d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of NANs before removal: 0\n",
            "Number of NaNs after removal: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for Duplicates\n",
        "duplicates_before = df.duplicated().sum()\n",
        "print(f\"Number of duplicate rows before removal: {duplicates_before}\")\n",
        "df.drop_duplicates(inplace=True)\n",
        "duplicates_after = df.duplicated().sum()\n",
        "print(f\"Number of duplicate rows after removal: {duplicates_after}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sTg6TWzF6wgS",
        "outputId": "f56f0d9a-ceb3-467e-c5b8-a2869e6f19a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of duplicate rows before removal: 348435\n",
            "Number of duplicate rows after removal: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(\"Class Distribution\")\n",
        "# print(df['intrusion_type'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66E_rXNzuD6g",
        "outputId": "226b7540-fcec-4c04-aef3-c60fc4a8dd39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class Distribution\n",
            "intrusion_type\n",
            "11.0    87832\n",
            "9.0     51820\n",
            "0.0       968\n",
            "20.0      918\n",
            "17.0      906\n",
            "21.0      893\n",
            "5.0       651\n",
            "18.0      641\n",
            "15.0      416\n",
            "14.0      206\n",
            "10.0      158\n",
            "3.0        53\n",
            "1.0        30\n",
            "22.0       20\n",
            "6.0        19\n",
            "4.0        12\n",
            "16.0       10\n",
            "7.0         9\n",
            "2.0         8\n",
            "8.0         7\n",
            "13.0        4\n",
            "12.0        3\n",
            "19.0        2\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split into Train and Test\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x = df.drop(columns='intrusion_type')\n",
        "y = df['intrusion_type']\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, stratify=y, random_state=42) # 80:20"
      ],
      "metadata": {
        "id": "PSjXUTzy9NHe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Forest\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "\n",
        "def RandomForest(x_train, y_train, x_test, y_test):\n",
        "  rf = RandomForestClassifier(random_state=42)\n",
        "  rf.fit(x_train, y_train)\n",
        "\n",
        "  y_pred = rf.predict(x_test)\n",
        "  accuracy = accuracy_score(y_test, y_pred)\n",
        "  f1 = f1_score(y_test, y_pred, average='macro')\n",
        "\n",
        "  print(\"Classification Report\")\n",
        "  print(classification_report(y_test, y_pred))\n",
        "\n",
        "  print(f\"Accuracy: {accuracy}\")\n",
        "  print(f\"F1 Score: {f1}\")\n",
        "\n",
        "  return accuracy, f1"
      ],
      "metadata": {
        "id": "QTJILBFhxnf5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reference: https://github.com/atulpatelDS/Youtube/blob/main/Machine_Learning/Imbalanced_Dataset_Handling/Different%20Techniques%20to%20deal%20with%20Imbalanced%20Dataset%20(Imbalanced%20Classes)%20in%20Machine%20Learning.ipynb\n",
        "# Random Oversampling with Smoothing\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "def random_oversampling(x_train, y_train):\n",
        "  ros = RandomOverSampler()\n",
        "  x_train_ros, y_train_ros = ros.fit_resample(x_train, y_train)\n",
        "  return x_train_ros, y_train_ros\n",
        "  # print(f\"x_train_ros shape: {x_train_ros.shape}, y_train_ros shape: {y_train_ros.shape}\")"
      ],
      "metadata": {
        "id": "XSzLN8GA1XuN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Oversampling with Smoothing (for nonaugmented dataset)\n",
        "acc_non_aug, f1_non_aug = RandomForest(x_train, y_train, x_test, y_test)"
      ],
      "metadata": {
        "id": "dbVm3A9R135-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cb8c857-80c4-47df-89bd-48e5700d3874"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      0.99      1.00       194\n",
            "         1.0       0.67      0.67      0.67         6\n",
            "         2.0       0.00      0.00      0.00         2\n",
            "         3.0       1.00      1.00      1.00        11\n",
            "         4.0       1.00      0.50      0.67         2\n",
            "         5.0       1.00      0.98      0.99       130\n",
            "         6.0       1.00      0.75      0.86         4\n",
            "         7.0       0.00      0.00      0.00         2\n",
            "         8.0       0.00      0.00      0.00         1\n",
            "         9.0       1.00      1.00      1.00     10364\n",
            "        10.0       0.97      0.97      0.97        32\n",
            "        11.0       1.00      1.00      1.00     17567\n",
            "        13.0       1.00      1.00      1.00         1\n",
            "        14.0       1.00      1.00      1.00        41\n",
            "        15.0       0.98      1.00      0.99        83\n",
            "        16.0       0.00      0.00      0.00         2\n",
            "        17.0       0.99      0.99      0.99       181\n",
            "        18.0       1.00      0.98      0.99       128\n",
            "        20.0       1.00      1.00      1.00       184\n",
            "        21.0       0.99      0.98      0.99       179\n",
            "        22.0       0.75      0.75      0.75         4\n",
            "\n",
            "    accuracy                           1.00     29118\n",
            "   macro avg       0.78      0.74      0.76     29118\n",
            "weighted avg       1.00      1.00      1.00     29118\n",
            "\n",
            "Accuracy: 0.9990727385122604\n",
            "F1 Score: 0.7551293198861161\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Oversampling with Smoothing (for augmented dataset)\n",
        "x_train_ros, y_train_ros = random_oversampling(x_train, y_train)\n",
        "acc_aug, f1_aug = RandomForest(x_train_ros, y_train_ros, x_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0AADkWsw-HmY",
        "outputId": "ca2bff5d-d5c9-4351-b9a6-90cb6f1c276c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      0.99      0.99       194\n",
            "         1.0       1.00      0.67      0.80         6\n",
            "         2.0       1.00      0.50      0.67         2\n",
            "         3.0       1.00      1.00      1.00        11\n",
            "         4.0       1.00      0.50      0.67         2\n",
            "         5.0       1.00      0.99      1.00       130\n",
            "         6.0       1.00      1.00      1.00         4\n",
            "         7.0       1.00      0.50      0.67         2\n",
            "         8.0       0.00      0.00      0.00         1\n",
            "         9.0       1.00      1.00      1.00     10364\n",
            "        10.0       1.00      0.97      0.98        32\n",
            "        11.0       1.00      1.00      1.00     17567\n",
            "        13.0       1.00      1.00      1.00         1\n",
            "        14.0       1.00      1.00      1.00        41\n",
            "        15.0       0.98      0.99      0.98        83\n",
            "        16.0       0.00      0.00      0.00         2\n",
            "        17.0       0.99      0.99      0.99       181\n",
            "        18.0       1.00      1.00      1.00       128\n",
            "        20.0       1.00      1.00      1.00       184\n",
            "        21.0       0.99      0.98      0.99       179\n",
            "        22.0       1.00      0.75      0.86         4\n",
            "\n",
            "    accuracy                           1.00     29118\n",
            "   macro avg       0.90      0.80      0.84     29118\n",
            "weighted avg       1.00      1.00      1.00     29118\n",
            "\n",
            "Accuracy: 0.9991757675664538\n",
            "F1 Score: 0.8375445353913546\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Metrics\n",
        "print(f\"Non-Augmented Accuracy: {acc_non_aug}\")\n",
        "print(f\"Non-Augmented F1 Score: {f1_non_aug}\")\n",
        "print(f\"Augmented Accuracy: {acc_aug}\")\n",
        "print(f\"Augmented F1 Score: {f1_aug}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rlYWU_rCxzn0",
        "outputId": "6b327c65-36f7-447b-d80f-8d61a170b79c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Non-Augmented Accuracy: 0.9990727385122604\n",
            "Non-Augmented F1 Score: 0.7551293198861161\n",
            "Augmented Accuracy: 0.9991757675664538\n",
            "Augmented F1 Score: 0.8375445353913546\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SMOTE-NC (for augmented dataset)"
      ],
      "metadata": {
        "id": "iQZal6hB0wLZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SMOTE-NC (for nonaugmented dataset)"
      ],
      "metadata": {
        "id": "VTH-h7L52BWA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}